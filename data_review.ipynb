{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5486, 0.4514, 0.0000, 0.0000],\n",
       "        [0.2338, 0.0510, 0.7152, 0.0000],\n",
       "        [0.6127, 0.0382, 0.0181, 0.3310]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tgt_ids = torch.randn(3,4)\n",
    "scores = torch.randn(4,4)\n",
    "mask = torch.triu(torch.ones((tgt_ids.shape[-1], tgt_ids.shape[-1])), diagonal=1)#.type(torch.uint8)\n",
    "\n",
    "scores.masked_fill(mask==1, -99999).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def attn_mask(src_ids=None, tgt_ids=None):\n",
    "    # encoder的掩码 正方形\n",
    "    if tgt_ids == None:\n",
    "        src_ids = torch.tensor(src_ids)\n",
    "        mask = torch.matmul(src_ids.unsqueeze(-1), src_ids.unsqueeze(1)).type(torch.uint8)\n",
    "        return mask\n",
    "\n",
    "    # decoder第一层的掩码，返回的是一个上三角为1的矩阵(对角线上的没有操作为1)\\\n",
    "    # 因为统一是mask==0 进行填充所以这里反一下 返回的地方让 上三角=false，\\\n",
    "    # 这样就等于0 将在self-attention填充，正方形\n",
    "    elif src_ids == None:\n",
    "        tgt_ids = torch.tensor(tgt_ids)\n",
    "        mask = torch.triu(torch.ones((tgt_ids.shape[-1], tgt_ids.shape[-1])), diagonal=1).type(torch.uint8)\n",
    "        return mask == 0\n",
    "\n",
    "    # decoder第二层cro_mask的掩码，kv来自encoder，q和kv的形状可能不同，长方形\n",
    "    else:\n",
    "        Q= torch.tensor(tgt_ids)\n",
    "        KV = torch.tensor(src_ids)\n",
    "        mask = torch.matmul(Q.unsqueeze(-1), KV.unsqueeze(1)).type(torch.uint8)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(1,40, (2,3))\n",
    "y = torch.randint(1,40, (2,5))\n",
    "attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "while a<10:\n",
    "    a +=1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kai(num, sqrt, acc):\n",
    "\n",
    "    tem = 0.01\n",
    "    acc_now = num - tem**sqrt\n",
    "    while acc_now >= acc:\n",
    "        midden = (num-tem)/2\n",
    "        if midden**sqrt > num:\n",
    "            left, right = tem, midden\n",
    "            midden = (left-right)/2\n",
    "\n",
    "        elif midden**sqrt < num:\n",
    "            left, right = midden, num\n",
    "            midden = (left-right)/2\n",
    "        \n",
    "        else:\n",
    "            return tem\n",
    "    print(tem)\n",
    "    \n",
    "    return tem\n",
    "\n",
    "a = kai(3, 2, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = sorted([i for i in range(10)], reverse=True)\n",
    "ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a8157aaf10863b2a25833f54889906938781f2222a5f87aac536d99914d8d6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
